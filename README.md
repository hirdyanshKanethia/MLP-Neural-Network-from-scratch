# Overview
This project is a **from-scratch implementation** of a **Multilayer Perceptron (MLP) Neural Network**, built without relying on deep learning libraries. It includes:

- **Core Components**: Custom implementations of matrix and NumPy-like operations to handle matrix operations.
- **Key Algorithms**: Backpropagation, gradient descent, and batch training â€” the fundamental building blocks behind training neural networks.
- **Interactive Web App**: A React-based interface (inspired by the [Keras Neural Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.41890&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)) to visualize and interact with the neural network in real time.
- **Use Case**: Demonstrates solving the classic **XOR classification problem**, a canonical example of a non-linearly separable task.

This project serves both as an educational resource for understanding how neural networks work under the hood and as an interactive tool for experimenting with different network configurations.
